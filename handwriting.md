     人类的视觉系统是世界的一个奇迹，下面是一串手写的数字


   人们可以轻松认出来这些数字是504192。非常简单。在我们大脑的每一个区域，人类有一个主要的视觉区，叫做V1，它由14亿个视觉细胞构成，这些视觉细胞之间形成了百亿数量级的连接。人类的视觉系统不仅仅有V1，还有V2，V3，V4，和V5. 它们一起组成了复杂的渐进式视觉处理系统。事实上，我们脑袋中有一台超级计算机，经过几亿年的进化和调校，形成了超常的视觉认知能力。实际上，识别手写字体绝非易事。我们人类在认知眼睛所看到的事物时时有着让人惊讶的能力。更神奇的是，整个识别的过程在我们无意识中就完成了。因此，我们经常忽视我们视觉系统这一超能力。

  但，当你准备用计算机程序来完成这一识别上述手写字体的过程时，就会感到十分困难。原本开起来对于我们来说易如反掌的事情突然变得极端困难。例如对9的识别，直觉上，9的特征是顶部一个圆圈，其下面是一个垂直的竖线，直达底部，这通过计算机算法描述起来却没这么简单。当你试图让这些特征精确起来，你会发现自己很快就迷失在无尽的特例和异常情况中。看起来简直不可能。

   神经网络试图从另外一个角度解决这个问题。方法是通过大量的手写字体也就是训练集，构建一个可以学习这些训练集的系统。也就是说，神经网络通过这些手写数字训练集自动找到识别它们的规律。然后，通过增加训练集的规模，神经网络可以学习更多手写体，逐渐提升识别的准确性。上面是100个训练集的例子，如果有一千个、一百万个甚至几十亿个训练集，我们可以构建一个更好的手写识别系统。
   这一张中，我们将写一个由计算机程序实现的神经网络，来识别手写字体。其实仅仅需要74行代码就够了，甚至不需要特殊的神经网络库。别小瞧这个神经网络，不需要人工干预，它的识别准确性就可达到96%。在后续的章节中，我们还会将它的识别率提升到99%。现实中最好的商业化神经网络已经足够好，银行已经在用它来识别支票，邮局用它识别地址。

   手写体的识别对于我们学习神经网络是一个非常棒的典型问题，后续我们也会聚焦在手写识别上。手写体识别有不是一个简单的问题，有一定的挑战性，但也不至于过于复杂而需要非常复杂的解决方案，也不需要海量的计算能力。此外，对于学习诸如深度学习一类的更高级一些的技术也有帮助。此书自始至终将不断回到手写体识别这个问题上来。后面，我们还将讨论如何将之应用到其它领域，例如计算机视觉、语音识别、自然语言的处理等等。

   当然，如果这一章的目的只是写一个能够识别手写字体的程序，这章将会非常短。我们还将涉及神经网络的相关的一些概念，包括两个重要的人工神经元(感知神经元和sigmoid神经元)，以及标准的神经网络学习算法，也就是梯度下降算法。我将着重解释为什么问题是这样解决的，帮助你建立神经网络的直观印象。除了我给大家介绍基本的机制之外，还需要进行更为深入的探讨。不过这对于你的更进一步理解会十分有帮助。这一章结束时，我们将了解到什么是深度学习，以及它的重要性。

## 感知神经网络

什么是神经网络？我们先解释下人工神经网络的一种，感知神经网络。1950 - 1960年代，受到Warren McCulloch 和 Walter Pitts的启发，科学家Frank Rosenblatt提出了感知神经网络的概念。今天，通常我们使用另外一种人工神经元，名字为sigmoid神经元。这本书也将重点探讨这种神经元。很快我们就将开始探讨它。不过，为了理解为什么sigmoid神经元被定义为他们的样子，我先介绍一下感知神经元(perceptrons).

perceptrons是如何工作的呢？一个perceptrons有数个二级制的输入x1,x2,...，处理结果是一个二进制的输出。

这个例子中，perceptrons有三个输入，x1,x2,x3，实际上，输入可能会更多或者更少。Rosenblatt提出了一个计算输出的简单规则。他引入了weights权重的概念，w1,w2,...，每个权重是一个实数，它代表了每个输入因素对输出结果的影响程度。神经元的输出，0或1，取决于权重w与i相乘然后求和的结果，如果大于某个阈值，则为1，否则为0.阈值是神经元的一个参数，它也是实数。可以用更精确一些的算法表示如下：

这就是一个perceptron是如何工作的。

这是一个很基础的数学模型。你可以一个perceptron看做是装置，它通过衡量凭据及其权重来进行决策。举个不太现实但容易理解的例子，稍后我们将举个更为现实的例子。周末就要来了，你听说你所在的城市将举行一个芝士节活动。你非常喜欢吃芝士，正在考虑是否要参加。你会考虑三个因素：

1. 天气是否晴朗
2. 你的女朋友/女朋友是否也愿意去
3. 地点公共交通是否便利(你不开车)

   用三个变量来代表这三个因素：x1,x2和x3。比如如果天气不错，x1 = 1；如果x1 = 0，就以为这天气很糟糕。同样，x2 = 1 意味着你女朋友/女朋友愿意去， x2 = 0为不愿意。x3同样。
现在加入你是只是的狂热爱好者，即使交通不便利，你女朋友/女朋友也不愿去，你还是会高高兴兴参加。但你非常讨厌糟糕的天气，如果天气不过，你绝对不会去。你可以使用perceptron来构建你的决策模型。其中一个办法是设代表天气的w1设为6，其它两个因素 w2 = 2， w3=2.w1的值很高，意味着天气对你的决策影响很大，远远超过另外两个因素。若你选择的阈值为5，则最终如果天气好，最终输出的结果就会大于1，相反，只要天气不好，结果就为0.输出的结果与你女朋友/男朋友愿不愿意去或者交通是否方便并没有关系。

   调整权重和阈值，可以得到不同的决策模型。例如，如果阈值设置为3，无论天气好与坏，或者举办地点交通很便利且你女朋友/男朋友愿意去，perceptron将最终决定你是否参加芝士节。就变为了一个不同的决策模型。降低阈值则意味着你更愿意参加芝士节。
   
   很明显，perceptron不是一个完整的人类决策模型，我们仍然可以清楚看到perceptron如何通过对各个因素施加权重来进行决策的。不过，看起来，通过一个复杂的perceptrons网络做细致的决定似乎是可行的。

   在这个网络中，perceptrons的第一列（第一层perceptrons）通过对输入设置权重，做了3个简单的决定。那perceptrons第二层会怎么做呢？第二层的perceptrons都会将第一层的perceptrons的输出作为输入，配以权重后，得出自己的结果。这样，相对于第一层的perceptrons，第二层的perceptron能够做出更复杂更抽象的决策。第三层perceptron，更为甚之。这样下去，有许多层perceptron构成的网络就可以做出复杂的决策。
    当我定义perceptron时我说过一个perceptron只有一个输出结果。在上述网络中，perceptron似乎有多个输出结果。事实上，它们仍然是单一输出结果。多个输出的箭头不过是为了方便我们理解一层perceptron的输出是其后层perceptron的输入而已。如果画一条输出线然后将它分为几节，会显得有些混乱。
   我们来简化一下perceptrons的描述。条件xxxx看起来蛮头疼的，我们可以用两个标记来改善一下。第一个改变是把xxx改为一个dot product，xxxx， 这里w和x是向量，分别代表权重和输入。第二个改变是把阈值挪到不等式的另外一边，并用perceptrons的bias来代替，b=-threshold. 使用偏移量替换到阈值，perceptrons规则就可以写作：

xxxx


   你可以把偏移量理解为输出结果为1的难以程度。或者，如果用生物学术语，偏移量意味着让perceptron的难以程度。如果一个perceptrons有一个非常大的偏移量，perceptrons输出结果为1就非常容易。反之，如果为很大的负值，输出结果为1就变得十分困难。很明显，引入偏移量只是我们描述perceptrons时的一个小变化。稍后，我们将会了解到它是如何帮助简化符号。因此，本书中，我们将一直使用偏移量这个术语而不是阈值。
   
  我已经把perceptrons描述为通过权衡各个输入变量来进行决策。perceptrons的另外一个用途是用做数据计算的基础的逻辑函数，诸如AND，OR，或者NAND。 例如，一个perceptron有两个输入，每一个权重是-2，整体的偏移量是3，perceptrons是这样的：


输入若为00则输出为1，因为(−2)∗0+(−2)∗0+3=3为正数。这里，我引进了*符号以便使乘法更加明确。类似的，如果输入为01或者10，结果也是1.但如果输入为11则输出为0，因为 (−2)∗1+(−2)∗1+3=−1为负值。由此可见，perceptron实现了NAND门。
  NAND门的例子可以看出可以使用perceptron来计算简单的逻辑函数。事实上，我们可以通过perceptron网络来计算任意的逻辑函数。原因是NAND门是一个通用的计算式，任何计算都可以通过组合NAND门来完成。例如，我们可以通过NAND门组合建立一个电路，功能是完成x1和x2相加。这需要计算二级制的加法，x1⊕x2，同事，当x1和x2都是1时，carry bit被设置为1。也就是说，carry bit只是按位运算的x1,x2的结果。


xxx

用perceptron替换掉NAND可以得到一个同样功能的perceptrons网络，每个perceptron权重为-2，偏移量设置为3.于是一个决策网络诞生了。注意，为了方便画箭头，我把右下角的NAND门对应的perceptron移动了一点点。

xxx


另外一个值得注意的事情是，最左侧perceptron的输出两次被用作最底部perceptron的输入。在定义perceptron的时候，我可没说一个perceptron的输出不能同时两次被用作另外一个perceptron的输入。事实上，完全是可以的。但如果你真的不想这么做，也可以把两条线合并为一条线，然后把权重设置为-4就可以了。（如果还没有理解这是为什么，你应该停下来，花些时间弄明白它）。修改后的网络如下所示，所有未标出来的权重都为-2，所有的偏移量都为3，只有一个权重为-4：

xxxx

我们一直把x1和x2当做变量画在perceptron 网络的左侧，但通常情况下，会在perceptrons网络的左侧在加一层--- 输入层，来放置输入。
xxx
如下标记只用作输入perceptron，他只有输出，没有输入。
xxx
简化了的符号而已。这不意味着它是一个没有输入的perceptron。为了看清这一点，假设一个perceptron没有输入，权重*参数求和则永远为零，那么，如果b>0,则perceptron的输出为1，否则，perceptron输出为0，这就说明perceptron的输出为一个固定的值，而非我们预期的值(x1)。 最好别把输入perceptron当做真的perceptron，把它当做特殊的输出为预期值(x1,x2,...)特殊单元好了。

上面加法的例子，可以出perceptrons网络是如何模拟包含多个NAND门的电路的。NAND门在计算中是通用的，因此，perceptrons网络也可以用作通用计算。
  perceptrons的计算通用性揖让人信心满满同时也多少有些让人失望。信心满满是因为perceptron网络可以像其他计算设备那样强大。但同时，让人沮丧的是，看起来perceptron也只是一种NAND门而已。这绝非是个大新闻。
  不过，实际情况好一些。我们可以设计一个学习算法来自动人工神经元网络的调整权重和阈值。无需程序员直接干预，只需要外部输入即可完成调整。通过这些学习算法，我们能够以一种完全不同于传统逻辑门的方法来使用perceptrons网络。不必把NAND或者其他门电路清晰布局出来，神经网络会自己学习如何解决这个问题，甚至是一些通过直接设计电路解决起来极端困难的问题。

## sigmoid神经元






















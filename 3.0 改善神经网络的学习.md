
当一个高尔夫球手开始练习打高尔夫球的时候，他们往往会花大量的时间练习一个基础的挥杆动作。 然后，慢慢地，他们才会学习其它的击球动作，打高球，学习拉球和后仰球等等。所有这些都是基于他们基本的挥杆练习。同理，我们花了不少精力去理解反向传播算法，这就是我们的基础挥杆练习，是大多数神经网络工作的基础。这一章，我们将会探讨一系列优化原始反向传播算法的技术，从而改善网络的学习。

我们将介绍到的技术包括：选择一个更好的代价函数--- [交叉熵代价函数](http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function)；四个[正则化方法](http://neuralnetworksanddeeplearning.com/chap3.html#overfitting_and_regularization)(L1和L2正则，随机失活以及训练集的人工扩展),这些可以使得我们的网络在现有训练集的基础上能够更好地归纳；一个更好的[初始化偏移量](http://neuralnetworksanddeeplearning.com/chap3.html#weight_initialization)的方法;[一系列有助于选择好的超级函数的诀窍](http://neuralnetworksanddeeplearning.com/chap3.html#weight_initialization)。除此之外，我们也可以浅显概述一下[其它几个技术](http://neuralnetworksanddeeplearning.com/chap3.html#other_techniques)。这些内容相互之间并没有逻辑上的先后关联性，你大可以跳着读你自己感兴趣的部分。大部分的技术我们也将通过代码来实现，以提升第一章中提到的手写数字分类问题。

当然，在神经网络发展处的新技术中的许许多多技术中，这些仅仅是少数的几个。背后的哲学是，为了理解大量的技术，从深入研究少数几个最重要的技术是一个非常不错的入门方法。掌握了这些重要的技术，不仅仅了解他们本身，也有助于加深你理解当使用神经网络的时候，可能会产生什么的问题。需要的时候，你就可以快速理解而并运用其它技术。

## 交叉熵代价函数
当我们发现自己错了的时候，大部分人都会觉得不开心。 在我刚开始学习钢琴不久，我就开始在听众面前表演。我非常紧张，刚开始演奏，就把音调搞低了一个音高。我很困惑，知道有人指出来我的错误，我甚至无法继续演奏了。我当时非常尴尬。不过，尽管不那么让人开心，在错误中我们也会学习的非常快。你可以想象，我下一次演奏的时候，一定再也不会把音高弄错了。相反，当我们的错误没有很好清楚地定义的时候，我们的学习会很慢。

理想情况下，我们希望我们的神经网络可以从错误中很快地学习。但现实是这样吗？为了回答这个问题，我们举个简单的例子，只包含了一个神经元和一个输入。

![](http://neuralnetworksanddeeplearning.com/images/tikz28.png)

我们将训练这个神经元做些非常简单的事情：输入为1输出结果为0。 当然，这绝对小菜一碟，即使不用学习算法那，我们也可以手工很轻易找到合适的权重和偏移量。但对于使用梯度下降来学习权重和偏移量来说，这个问题很有启发性。我们仔细看一下神经元是怎么学习的。

明确起见，我们将初始权重设为0.6，初始偏移量为0.9。这是在学习开始常用的初始化方法。我并没有选择一些很特别的数值。神经元的初试输出为0.82. 看起来距离我们想要的输出0.0，还有挺多学习要做。你可以试着点击右下角的的运行按钮看看神经网络是如何学习，最终得到的输出为非常接近0.0。请注意，这里并不是一个预设好的动画效果，实际上你的浏览器在实时计算梯度，如何使用梯度来更新权重和偏移量。学习率$\eta = 0.15$，可以看到，它有些慢，不过我们可以跟上整个学习过程，而且可以在几秒钟就可以看完整个学习过程。这里用到的代价函数就是上一章我们提到过的二次代价函数C。我将会不时提醒你所使用代价函数的形式，所以，你不必来回找代价函数的定义。请注意，你可以多次点击"运行"按钮来观看网络的学习过程。

xxxx

如你所见，神经元可以快速地学习权重和偏移量来降低代价函数，最终网络的输出为0.09。虽然距离0.0还有些差距，不过已经相当不错了。不过，假如我们选择的初始权重和偏移量都是2.0.那么，出示输出为0.98，差得有些离谱。我们看下，这种情况下神经元是如何学习，最终得到输出为0的。请再次点击"运行"按钮。

xxxx

这个例子中，我们尽管选择了相同的学习率$\eta = 0.15$，前段部分的学习却十分缓慢。实际上，前150个世代的学习中，权重和偏移量的变化很微弱。然后，学习才突然加速，变得与第一个例子相似，神经元的输出快速趋向于0.0.

和人类的学习曲线相比，这个行为很奇怪。就如本章开头提到的那样，当人类在发现自己错的离谱的时候，往往会学习得非常快。不过，刚才我们看到的却是神经网络在初始阶段虽然错的离谱，学习速度却十分困难---要比错的没那么远的时候困难得多。其实，不仅仅是这个玩具模式的网络，更多通用的网络也有类似的情况。为什么学习会变慢呢？有办法可以避免这种情况吗？

为了找到这个问题的根源，想象一下，我们的神经元通过改变权重和偏移量进行学习，学习的速度取决于大家函数的导数，$ \frac{\partial C}{\partial w}$ 和$\frac{\partial C}{\partial b}$。所以，所谓的学些比较慢是技术上等同于说这些偏导数很小。挑战是弄清楚为什么会这样。我们来计算一下这个偏导数，我们用到的代价函数如下：

$ C = \frac{(y-a)^2}{2}, \qquad \qquad \qquad  (54) $

a是当输入$x=1$时，神经元的输出，y=0是期望的输出。为了更清楚一些，我们使用权重和偏移量来书写。回想一下，$a=\sigma(z)$，$z=wx+b$。运用链式法则可以得到：

$ \frac{\partial C}{\partial w} = (a-y)\sigma'(z)x = a\sigma'(z) \qquad \qquad \qquad  (55) $

$ \frac{\partial C}{\partial b} = (a-y)\sigma'(z)x = a\sigma'(z) \qquad \qquad \qquad  (56) $

这里我做了个替换$x = 1, y=0$。 为了理解这些表达式的意义，我们看一下等式右侧的$\sigma'(z)$。回忆一下$\sigma$函数：

![chart]()

当神经元的输出接近1的时候，曲线变得非常平坦，所以$\sigma'(z)$的值就很小。等式(55)和等式(56)告诉我们，$\frac{\partial C}{\partial b}$ 和 $\frac{\partial C}{\partial w}$就非常小。这就是学习缓慢的根源了。稍后我们会看到，学习缓慢不仅仅发生在这个玩具神经元网络中，在许多通用神经网络也经常发生。


## 介绍交叉熵代价函数

那如何解决学习缓慢的问题呢？方法是将二次代价函数换做一个新的代价函数，交叉熵函数。为了理解这个函数，我们先把超级简单的玩具网络模型放在一边。加入我们想训练一个神经元，它由多个变量$x_1,x_2,...，$对应的权重为$w_1,w_2,...$，偏移量为$b$:

![](http://neuralnetworksanddeeplearning.com/images/tikz29.png)

神经元的输出为$a=\sigma(z)$,这里$z=sum_j w_jx_j + b$是对所有的输入进行加权求和。这个神经元的交叉上函数定义如下：

$C = -\frac{1}{n} \sum_x [ylna + (1-y)ln(1-a)], \qquad \qquad \qquad  (57)$

这里$n$是训练数据的数量，求和是针对所有的训练集$x$，$y$是对应的期望的输出。

等式(57)可以避免学习缓慢的问题吗？现在还不太明显。甚至，坦率地说，很不太能看出来它是一个代价函数。弄明白它是如何解决学习缓慢之前，我们先看一下它为什么可以用作代价函数。

作为代价函数，它有两个特别的特性。第一，它非负数，C>0。请注意，(a)，等式(57)中，所有的单个元素都是负数，因为两个元素都是对介于0与1之间的数求对数。(b)，在求和运算符之前有一个负号。

第二，对于所有的输入x而言，如何神经元的实际输出接近于期望的输出，那么交叉熵函数的值接近于0.为了弄明白这一点，对于某个输入$x$,$y=0$并且$a \approx 0$。 这个案例中，神经元工作的非常好。因为$y=0$代价函数等式(57)右侧第一项消失了，第二项$-ln(1-a)\approx 0$.运用类似的分析，可以得到$y=1$的时候，$a \approx 1$。由于实际输出接近于期望值，所以它们对代价函数的贡献会比较低。

总结一下，交叉熵函数为正值，给定训练输入x，当神经元计算的结果接近于期望值y时， 交叉熵函数的值趋向0。这都是我们期望代价函数所具备的特性。实际上，二次代价函数也具备这两个特性。这对于交叉熵函数来说是个不错的消息。不仅仅如此，交叉熵函数拥有一个二次代价函数所不具备的特性，避免了学习缓慢的问题。为了证明这一点，我们计算一下交叉熵函数对权重的偏导数。我们把$a=\sigma(z)$代入等式(57),然后应用两次链式法则，就可以得到:

$\frac{\partial C}{\partial w} = -\frac{1}{n}\sum_x(\frac{y}{\sigma(z)}-\frac{1-y}{1-\sigma(z)})\frac{\partial \sigma}{\partial w_j} \qquad \qquad \qquad   (58)$ 

$= -\frac{1}{n}\sum_x(\frac{y}{\sigma(z)}-\frac{(1-y)}{1-\sigma(z)})\sigma'(z)x_j. \qquad \qquad \qquad   (59)$

把所有元素放在一个统一的分母上，然后进行简化，可以得到：

$\frac{\partial C}{\partial w} = \frac{1}{n}\sum_x \frac{\sigma'(z)x_j}{\sigma(z)(1-\sigma(z))}(\sigma(z)-y). \qquad \qquad \qquad   (60)$

运用sigmoid函数的定义$\sigma(z) = \frac{1}{1+e^{-z}}$,以及一些简单的代数计算，可以得到$\sigma'(z) - \sigma(z)(1-\sigma(z))$。在接下来的联系中，我会要求你去证明这一点，这里，我们先简单接受它。$\sigma'(z)$和$\sigma(z)(1-\sigma(z))$刚好和上述等式抵消，所以等式可以简化为：

$\frac{\partial}{\partial w_j} = \frac{1}{n}\sum_xx_j(\sigma(z)-y). \qquad \qquad \qquad  (61)$

这个等式很漂亮。它告诉我们权重学习的率(rate)取决于$\sigma(z)-y$，输出的误差就是其中的一个例子这就意味着，误差越大，神经元的学习越快。这恰好是我们所期望的。而且，他避免了二次代价函数中使得学习缓慢的$\sigma'(z)$,交叉熵函数消除掉了$\sigma'(z)$,再也不用担心因为它是的学习率变小了。这个消除是是交叉熵函数的一个奇迹。其实也不是奇迹，稍后我们将看到，交叉熵函数是我们精心挑选出来的。

同样，我们可以依此来计算偏移量的偏导数。细节这里不再赘述，你可以轻松证明以下等式：

$\frac{\partial C}{\partial b}= \frac{1}{n}\sum_x (\sigma(z)-y) \qquad \qquad \qquad  (62)$

再次规避了二次代价函数中让学习变得缓慢的$\sigma]'(z)$项。

## 练习

- 证明$\sigma'(z) = \sigma(z)(1-\sigma(z)).$

回到我们反复把玩的玩具案例，来看看在使用了交叉熵取代二次函数作为代价函数后，会发生什么。为了能够清楚说明这一点，我们以能够在二次代价函数下良好运作的初始权重0.6和偏移量0.9开始。请点击一下"运行按钮"来看看用交叉熵函数替代二次函数后会是怎样：

xxxx

没有任何问题，和早前一样，神经元学习的非常好。然后，我们在看看二次代价函数表现不太好的情况，我们把偏移量和权重都设置为2.0：

成功了！这次神经元仍然学习的很快，正如我们的预期。如果你仔细看一下，你会发现，初始阶段，在二次代价函数曲线比较平坦的部分，交叉熵代价函数的曲线却陡峭得多。这个交叉熵函数带来的陡峭，使得神经元终于在应该最快学习的时候(例如初始化偏差离谱的时候)，避免了卡壳。

我在这些例子中并未提到学习率。早先，在二次代价函数中，我们使用$\eta = 0.15$。在新的例子中，我们应该使用相同的学习率吗？事实上，因为更换了代价函数，对比学习率似乎也失去了意义。正如拿苹果来对比橘子。对于这两个例子，我只是简单地做了一些实验来找到一个合适的学习率，这样我们可以看清楚到底发生了什么。如果你真的很好奇，我把真想公布出来，刚才的案例中，我使用的学习率是$\eta = 0.005$。

你可能会提出反对，学习率的改变是的对比上述图表变得没有意义了。如果我们随意选择学习率，谁去关心神经元的学习速度呢？这个反对意见脱离了我们讨论的主体。以上图表不是想要标明绝对的学习速度，而且学习速度的变化。具体来说，使用二次代价函数的时候，神经元错的离谱时学习速度反而比之后接近正确输出时候还要慢；但对于交叉熵函数来说，错的越离谱，学习速度越快。这个结论和学习率无关。

我们已经学习了单个神经元的交叉熵函数，多个神经元多层神经网络下的交叉熵函数就不困难了。举个例子，设$y=y1,y2,...$是期望的输出神经元，例如 处于网络最后一层的神经元，$a_1^L,a_2^L,...$是实际的网络计算输出值。那么交叉熵函数如下：

$C = -\frac{1}{n}\sum_x\sum_j[y_jln a_j^L+(1-y_j)ln(1-a_j^L)]. \qquad \qquad \qquad  (63)$

这还之前的等式(57)的表达式相同，只不过多了一个$\sum_j$来对所有的输出神经元进行求和。这里就不继续求导了，不过，在很多神经网络中，使用了等式(63)就可以避免学习缓慢的问题。如果感兴趣，你可以自己去求导一下。

顺带提一下，我使用的属于交叉熵函数可能会对一些早期的读者产生困惑，从字面上看，它可能和其它人的叫法有些冲突。一般情况下，会把交叉熵函数定义为两个概率分布，$p_j$和$q_j$，函数为：$\sum_jp_jlnq_j$。这个定义和等式(57)关联性比较强。我们可以把单个sigmoid神经元的输出看作是由神经元激活值$a$及其补数$1-a$构成的概率分布。

不过，如果最后一层的sigmoid神经元有多个的时候，激活值向量$a_j^L$并不会形成概率分布。结果是，因为我们并不是基于概率分布工作的，像$\sum_jp_jlnq_j$的定义甚至失去了意义。相反，你可以把等式(63)当做是对一组单个神经元的交叉熵函数的进行求和，每一个神经元的激活值被解释为一个包含两个元素的概率分布。这种情况下，等式(63)就意味着是对概率分布的交叉熵函数的求和。

那我们应该在什么时候用交叉熵函数代替二次次代价函数呢？是事实上，只要我们选取的simgoid神经元，交叉熵函数几乎总是更好的选择。原因是，我们在初始化权重和偏移量的时候，总是会用随机化方法。所以，有可能我们的初试选择结果对于一些输入来说可能偏的离谱，这样输出神经元要么在0要么1附近饱和，这种情况下，如果使用二次代价函数，学习的速度就会减慢。当然学习不会停止，因为权重还是会不断地从训练输入中学习，不过学习的速度可能会让我们有些失望。

## 练习
- 交叉熵函数一个棘手的地方是比较难以记住y和a的对应的角色。优势比较难以弄清楚到底是$−[ylna+(1−y)ln(1−a)]$ 还是$−[ylna+(1−a)ln(1−y)]$。 对于第二个表达式，如果y=0或者1的时候，会发生什么呢？这个问题和第一个表达式有关吗？为什么？

- 本节开头我们讨论单个神经元的时候，我们讨论过，对于所有的训练样本来说，当$\sigma(z)\approx y$时，交叉熵函数会是个很小的值。这是基于y要么等于0要么等于1的假定。这对于分类问题往往是适用的，但对于其它问题(例如 回归问题)，y有些时候是介于0和1之间的中间值。此时，对于所有训练样本，当$\sigma(z) = y$时，交叉熵函数仍然是最小化的。这种情况下，交叉熵函数的也是有价值的：

$C = -\frac{1}{n}\sum_j[ylny + (1-y)ln(1-y)] \qquad \qquad \qquad  (64)$

$[ylny + (1-y)ln(1-y)]$有时也被叫做[二级制熵](http://en.wikipedia.org/wiki/Binary_entropy_function)。

## 问题

- 多层级多神经元网络
  
在上一章介绍的编辑中，我们可以看到在输出层，二次代价函数相对于权重的偏导数为：
$\frac{\partial C}{\partial w_{jk}^L} = \frac{1}{n}\sum_xa_k^{L-1}(a_j^L - y_j)\sigma'(z_j^L)\qquad \qquad \qquad (65)$

当初始化离谱时，输出神经元项饱和，因此$\sigma'(z_j^L)$这一项造成了学习缓慢。采用交叉熵作为代价函数时,单个训练样本$x$的输出误差为$\delta^L$：

$\delta^L = a^L -y \qquad \qquad \qquad (66)$

代入这个表达式后，在输出层对权重求偏导数的等式为：

$\frac{\partial C}{\partial w_{jk}^L = \frac{1}{n}\sum_xa_k^{L-1}(a_j^L - y_j)}. \qquad \qquad \qquad  (67)$

这里$\sigma'(z_j^L)$项消失了，所以交叉熵避免了学习缓慢的问题，这不仅仅对于单个神经元适用，对于多个层级多个神经元构成的网路也适用。稍微变换一下这个分析，你可以看到它对偏移量同样是适用的。如果你还没弄清楚，你需要花些时间自己弄明白它。











